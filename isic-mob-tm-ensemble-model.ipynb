{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9339772,"sourceType":"datasetVersion","datasetId":5660034},{"sourceId":109861,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":91923,"modelId":116131},{"sourceId":109862,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":91665,"modelId":115884},{"sourceId":111705,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":93615,"modelId":117825},{"sourceId":112336,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":93615,"modelId":117825},{"sourceId":112396,"sourceType":"modelInstanceVersion","modelInstanceId":93615,"modelId":117825}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lokotwist/isic-mob-tm-ensemble-model?scriptVersionId=196662691\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/lokotwist/isic-mob-tm-ensemble-model?scriptVersionId=196445572\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n\n\n# Normalize test data for this model\nx_valid = feats_test.astype('float32') / 255\ny_valid = to_categorical(labels_test, 5)\n\n# Load the model\nmodel = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set\nBS = 10\npred_Y = model.predict(x_valid, batch_size=BS, verbose=True)\n\n# Convert predictions and true labels to class indices\npred = np.argmax(pred_Y, axis=1)\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=class_names)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:27:40.516326Z","iopub.execute_input":"2024-09-09T16:27:40.516776Z","iopub.status.idle":"2024-09-09T16:27:56.683049Z","shell.execute_reply.started":"2024-09-09T16:27:40.516737Z","shell.execute_reply":"2024-09-09T16:27:56.682211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, pred)\nprint(f\"Model Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:28:04.186661Z","iopub.execute_input":"2024-09-09T16:28:04.187768Z","iopub.status.idle":"2024-09-09T16:28:04.193777Z","shell.execute_reply.started":"2024-09-09T16:28:04.187723Z","shell.execute_reply":"2024-09-09T16:28:04.192781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate the classification report\nreport = classification_report(rounded_labels, pred, target_names=['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer'])\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:28:10.978876Z","iopub.execute_input":"2024-09-09T16:28:10.979566Z","iopub.status.idle":"2024-09-09T16:28:10.995085Z","shell.execute_reply.started":"2024-09-09T16:28:10.979524Z","shell.execute_reply":"2024-09-09T16:28:10.993942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\n\n\n\n# Normalize test data for this model (Teachable Machine normalization)\nx_valid = (feats_test.astype('float32') / 127.5) - 1\ny_valid = to_categorical(labels_test, 5)\n\n# Load the model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set\nBS = 10\npred_Y = model2.predict(x_valid, batch_size=BS, verbose=True)\n\n# Convert predictions and true labels to class indices\npred = np.argmax(pred_Y, axis=1)\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=class_names)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T13:52:27.677708Z","iopub.execute_input":"2024-09-12T13:52:27.678784Z","iopub.status.idle":"2024-09-12T13:52:29.043689Z","shell.execute_reply.started":"2024-09-12T13:52:27.678731Z","shell.execute_reply":"2024-09-12T13:52:29.042219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize the test data using Teachable Machine normalization\nx_valid = (feats_test.astype('float32') / 127.5) - 1\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for the test set\npred_Y = model2.predict(x_valid, batch_size=10, verbose=True)\n\n# Convert predictions and true labels to class indices\npred = np.argmax(pred_Y, axis=1)\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Confusion Matrix Function\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, \"{:.2f}\".format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, pred)\n\n# Class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Confusion Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:29:34.358113Z","iopub.execute_input":"2024-09-09T16:29:34.358891Z","iopub.status.idle":"2024-09-09T16:29:49.631457Z","shell.execute_reply.started":"2024-09-09T16:29:34.358851Z","shell.execute_reply":"2024-09-09T16:29:49.630533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate the classification report\nreport = classification_report(rounded_labels, pred, target_names=['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer'])\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:30:23.996081Z","iopub.execute_input":"2024-09-09T16:30:23.996735Z","iopub.status.idle":"2024-09-09T16:30:24.011845Z","shell.execute_reply.started":"2024-09-09T16:30:23.996693Z","shell.execute_reply":"2024-09-09T16:30:24.010976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions (e.g., by averaging the predicted probabilities)\ncombined_pred_Y = (pred_Y_model1 + pred_Y_model2) / 2\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:19:57.798289Z","iopub.execute_input":"2024-09-09T15:19:57.799629Z","iopub.status.idle":"2024-09-09T15:22:46.233324Z","shell.execute_reply.started":"2024-09-09T15:19:57.799576Z","shell.execute_reply":"2024-09-09T15:22:46.232021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.65 * pred_Y_model1) + (0.35 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix with Weighted Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:32:01.620748Z","iopub.execute_input":"2024-09-09T15:32:01.621449Z","iopub.status.idle":"2024-09-09T15:32:31.520826Z","shell.execute_reply.started":"2024-09-09T15:32:01.621402Z","shell.execute_reply":"2024-09-09T15:32:31.519888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.6 * pred_Y_model1) + (0.4 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix with Weighted Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:33:02.85464Z","iopub.execute_input":"2024-09-09T15:33:02.855049Z","iopub.status.idle":"2024-09-09T15:33:32.39003Z","shell.execute_reply.started":"2024-09-09T15:33:02.85501Z","shell.execute_reply":"2024-09-09T15:33:32.389037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.68 * pred_Y_model1) + (0.32 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix with Weighted Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:06:26.279045Z","iopub.execute_input":"2024-09-09T16:06:26.279807Z","iopub.status.idle":"2024-09-09T16:06:56.295972Z","shell.execute_reply.started":"2024-09-09T16:06:26.27977Z","shell.execute_reply":"2024-09-09T16:06:56.29495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.68 * pred_Y_model1) + (0.32 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\nfrom sklearn.metrics import classification_report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:07:07.069521Z","iopub.execute_input":"2024-09-09T16:07:07.069898Z","iopub.status.idle":"2024-09-09T16:07:37.149247Z","shell.execute_reply.started":"2024-09-09T16:07:07.069864Z","shell.execute_reply":"2024-09-09T16:07:37.148162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.9 * pred_Y_model1) + (0.1 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\nfrom sklearn.metrics import classification_report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:50:18.033535Z","iopub.execute_input":"2024-09-09T15:50:18.033856Z","iopub.status.idle":"2024-09-09T15:50:47.976354Z","shell.execute_reply.started":"2024-09-09T15:50:18.033822Z","shell.execute_reply":"2024-09-09T15:50:47.975405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.75, 0.8, 0.5, 0.72])  # Model 1 precision\nweights_model2 = np.array([0.4, 0.25, 0.2, 0.5, 0.28])  # Model 2 precision\n\n# Ensure weights are applied to each prediction\ncombined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n\n# Normalize the combined predictions (optional, but usually recommended)\ncombined_pred_Y /= (weights_model1 + weights_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:58:54.980466Z","iopub.execute_input":"2024-09-09T16:58:54.981156Z","iopub.status.idle":"2024-09-09T16:58:55.000174Z","shell.execute_reply.started":"2024-09-09T16:58:54.981117Z","shell.execute_reply":"2024-09-09T16:58:54.99933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.75, 0.8, 0.5, 0.72])  # Model 1 precision\nweights_model2 = np.array([0.4, 0.25, 0.2, 0.5, 0.28])  # Model 2 precision\n\n# Ensure weights are applied to each prediction\ncombined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n\n# Normalize the combined predictions (optional, but usually recommended)\ncombined_pred_Y /= (weights_model1 + weights_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Function to plot the confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=target_names, title='Combined Confusion Matrix with Class-Specific Weights')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:42.541571Z","iopub.execute_input":"2024-09-12T14:05:42.542065Z","iopub.status.idle":"2024-09-12T14:06:07.04249Z","shell.execute_reply.started":"2024-09-12T14:05:42.542018Z","shell.execute_reply":"2024-09-12T14:06:07.040203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.75, 0.8, 0.5, 0.72])  # Model 1 precision\nweights_model2 = np.array([0.4, 0.25, 0.2, 0.5, 0.28])  # Model 2 precision\n\n# Ensure weights are applied to each prediction\ncombined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n\n# Normalize the combined predictions (optional, but usually recommended)\ncombined_pred_Y /= (weights_model1 + weights_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Function to plot the confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=target_names, title='Combined Confusion Matrix with Class-Specific Weights')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:17:16.914982Z","iopub.execute_input":"2024-09-09T17:17:16.915903Z","iopub.status.idle":"2024-09-09T17:17:17.361532Z","shell.execute_reply.started":"2024-09-09T17:17:16.915859Z","shell.execute_reply":"2024-09-09T17:17:17.360527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])  # Model 1 precision\nweights_model2 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])  # Model 2 precision\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n        image_model1 = image_array.astype('float32') / 255\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Get the top 2 predicted classes and their confidence\n    top_2_indices = np.argsort(combined_pred_Y[0])[-2:][::-1]\n    \n    # Get the top 2 confidence scores\n    top_2_confidences = combined_pred_Y[0][top_2_indices] * 100\n    \n    # Display the results\n    print(f\"Top 1 Predicted Class: {class_names[top_2_indices[0]]}\")\n    print(f\"Confidence: {top_2_confidences[0]:.2f}%\")\n    print(f\"Top 2 Predicted Class: {class_names[top_2_indices[1]]}\")\n    print(f\"Confidence: {top_2_confidences[1]:.2f}%\")\n    \n    # Plot the image\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Top 1: {class_names[top_2_indices[0]]} ({top_2_confidences[0]:.2f}%)\\n\"\n              f\"Top 2: {class_names[top_2_indices[1]]} ({top_2_confidences[1]:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T13:41:34.897377Z","iopub.execute_input":"2024-09-12T13:41:34.897764Z","iopub.status.idle":"2024-09-12T13:42:26.738737Z","shell.execute_reply.started":"2024-09-12T13:41:34.897721Z","shell.execute_reply":"2024-09-12T13:42:26.737567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load the model\n# model = load_model('/kaggle/working/isic4k50_model_v5.h5')\nmodel = load_model('/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5')\n\n# Dictionary for class labels\nclass_dict = {\n    0: \"Basal_Cell_Carcinoma\",\n    1: \"Melanoma\",\n    2: \"Nevus\",\n    3: \"Benign_keratosis\",\n    4: \"No_cancer\"\n}\n\n# Helper function to preprocess image and make predictions\ndef process_image(img, model):\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255   \n    preds = model.predict(img_array)[0]\n    return preds\n\n# Function to process image from URL or File\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).resize((224, 224))\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).resize((224, 224))\n    return img\n\n# Function to display prediction as a bar chart with transparent background\ndef display_prediction(preds, class_dict):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    classes = list(class_dict.values())\n    confidences = preds * 100\n    \n    ax.barh(classes, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Function to handle the prediction process\ndef handle_prediction(img, model, class_dict):\n    preds = process_image(img, model)\n    display_image(img)\n    display_prediction(preds, class_dict)\n    pred_class = np.argmax(preds)\n    confidence = preds[pred_class] * 100\n    print(f\"\\nPredicted class: {class_dict[pred_class]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n\n# Function to display the input image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_path = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_path)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img, model, class_dict)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T15:32:22.766068Z","iopub.execute_input":"2024-09-12T15:32:22.766544Z","iopub.status.idle":"2024-09-12T15:32:24.258703Z","shell.execute_reply.started":"2024-09-12T15:32:22.766499Z","shell.execute_reply":"2024-09-12T15:32:24.25731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load the model\n# model = load_model('/kaggle/working/isic4k50_model_v5.h5')\nmodel = load_model('/kaggle/input/isic6k/keras/default/2/mobilenetv2_model_v7.h5')\n\n# Dictionary for class labels\nclass_dict = {\n    0: \"Basal_Cell_Carcinoma\",\n    1: \"Melanoma\",\n    2: \"Nevus\",\n    3: \"Benign_keratosis\",\n    4: \"No_cancer\"\n}\n\n# Helper function to preprocess image and make predictions\ndef process_image(img, model):\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255   \n    preds = model.predict(img_array)[0]\n    return preds\n\n# Function to process image from URL or File\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).resize((224, 224))\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).resize((224, 224))\n    return img\n\n# Function to display prediction as a bar chart with transparent background\ndef display_prediction(preds, class_dict):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    classes = list(class_dict.values())\n    confidences = preds * 100\n    \n    ax.barh(classes, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Function to handle the prediction process\ndef handle_prediction(img, model, class_dict):\n    preds = process_image(img, model)\n    display_image(img)\n    display_prediction(preds, class_dict)\n    pred_class = np.argmax(preds)\n    confidence = preds[pred_class] * 100\n    print(f\"\\nPredicted class: {class_dict[pred_class]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n\n# Function to display the input image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_path = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_path)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img, model, class_dict)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T15:31:29.440166Z","iopub.execute_input":"2024-09-12T15:31:29.441164Z","iopub.status.idle":"2024-09-12T15:31:31.09244Z","shell.execute_reply.started":"2024-09-12T15:31:29.441093Z","shell.execute_reply":"2024-09-12T15:31:31.091284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load the model\n# model = load_model('/kaggle/working/isic4k50_model_v5.h5')\nmodel = load_model('/kaggle/input/isic6k/keras/default/1/xception_model_v6.h5')\n\n# Dictionary for class labels\nclass_dict = {\n    0: \"Basal_Cell_Carcinoma\",\n    1: \"Melanoma\",\n    2: \"Nevus\",\n    3: \"Benign_keratosis\",\n    4: \"No_cancer\"\n}\n\n# Helper function to preprocess image and make predictions\ndef process_image(img, model):\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    preds = model.predict(img_array)[0]\n    return preds\n\n# Function to process image from URL or File\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).resize((224, 224))\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).resize((224, 224))\n    return img\n\n# Function to display prediction as a bar chart with transparent background\ndef display_prediction(preds, class_dict):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    classes = list(class_dict.values())\n    confidences = preds * 100\n    \n    ax.barh(classes, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Function to handle the prediction process\ndef handle_prediction(img, model, class_dict):\n    preds = process_image(img, model)\n    display_image(img)\n    display_prediction(preds, class_dict)\n    pred_class = np.argmax(preds)\n    confidence = preds[pred_class] * 100\n    print(f\"\\nPredicted class: {class_dict[pred_class]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n\n# Function to display the input image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_path = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_path)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img, model, class_dict)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T15:32:40.275767Z","iopub.execute_input":"2024-09-12T15:32:40.276273Z","iopub.status.idle":"2024-09-12T15:32:42.726201Z","shell.execute_reply.started":"2024-09-12T15:32:40.276214Z","shell.execute_reply":"2024-09-12T15:32:42.724894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\n\n# Load the model\nmodel = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\ndef preprocess_image(img):\n    # Resize the image to (224, 224) and crop from the center if needed\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    \n    # Convert to array\n    img_array = np.asarray(img)\n    \n    # Normalize the image\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    \n    # Expand dimensions to create batch\n    img_array = np.expand_dims(img_array, axis=0)\n    \n    return img_array\n\ndef predict_skin_cancer(img):\n    # Preprocess the image\n    processed_image = preprocess_image(img)\n    \n    # Make prediction\n    predictions = model.predict(processed_image)\n    \n    # Get the predicted class index\n    predicted_class_index = np.argmax(predictions[0])\n    \n    # Get the predicted class name\n    predicted_class = class_names[predicted_class_index]\n    \n    # Get the confidence score as a percentage\n    confidence = predictions[0][predicted_class_index] * 100\n    \n    # Convert all probabilities to percentages\n    probabilities_percentage = predictions[0] * 100\n    \n    return predicted_class, confidence, probabilities_percentage\n\n# Prompt user for image URL\nimg_url = input(\"Enter the URL of the image: \")\n\ntry:\n    # Load the image from URL\n    response = requests.get(img_url)\n    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    \n    # Perform prediction\n    predicted_class, confidence, all_probabilities = predict_skin_cancer(image)\n\n    print(f\"Predicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, probability in zip(class_names, all_probabilities):\n        print(f\"{class_name}: {probability:.2f}%\")\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:58:51.964898Z","iopub.execute_input":"2024-09-12T14:58:51.965488Z","iopub.status.idle":"2024-09-12T14:58:56.526352Z","shell.execute_reply.started":"2024-09-12T14:58:51.965442Z","shell.execute_reply":"2024-09-12T14:58:56.525211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.4, 0.4, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.6, 0.6, 0.4, 0.5])\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n        image_model1 = image_array.astype('float32') / 255\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Get the predicted class and confidence\n    predicted_class_idx = np.argmax(combined_pred_Y)\n    confidence = combined_pred_Y[0][predicted_class_idx] * 100\n    \n    # Display the results\n    print(f\"Predicted Class: {class_names[predicted_class_idx]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    \n    # Plot the image\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:12:40.084625Z","iopub.execute_input":"2024-09-12T14:12:40.085575Z","iopub.status.idle":"2024-09-12T14:13:00.942967Z","shell.execute_reply.started":"2024-09-12T14:12:40.08552Z","shell.execute_reply":"2024-09-12T14:13:00.941799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\nweights_model2 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n        image_model1 = image_array.astype('float32') / 255\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Display the prediction percentages for all classes\n    print(\"Class prediction percentages:\")\n    for i, class_name in enumerate(class_names):\n        confidence = combined_pred_Y[0][i] * 100\n        print(f\"{class_name}: {confidence:.2f}%\")\n    \n    # Get the predicted class and confidence for the top prediction\n    predicted_class_idx = np.argmax(combined_pred_Y)\n    confidence = combined_pred_Y[0][predicted_class_idx] * 100\n    \n    # Plot the image with the predicted class and confidence\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:20:23.962105Z","iopub.execute_input":"2024-09-12T14:20:23.962709Z","iopub.status.idle":"2024-09-12T14:20:35.203581Z","shell.execute_reply.started":"2024-09-12T14:20:23.962655Z","shell.execute_reply":"2024-09-12T14:20:35.2022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\nweights_model2 = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n#         image_model1 = image_array.astype('float32') / 255\n        image_model1 = (image_array.astype('float32') / 127.5) - 1\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Display the prediction percentages for all classes\n    print(\"Class prediction percentages:\")\n    for i, class_name in enumerate(class_names):\n        confidence = combined_pred_Y[0][i] * 100  # Convert to percentage\n        print(f\"{class_name}: {confidence:.2f}%\")\n    \n    # Get the predicted class and confidence for the top prediction\n    predicted_class_idx = np.argmax(combined_pred_Y)\n    confidence = combined_pred_Y[0][predicted_class_idx] * 100  # Convert to percentage\n    \n    # Plot the image with the predicted class and confidence\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:23:34.925111Z","iopub.execute_input":"2024-09-12T14:23:34.926422Z","iopub.status.idle":"2024-09-12T14:23:44.989744Z","shell.execute_reply.started":"2024-09-12T14:23:34.92635Z","shell.execute_reply":"2024-09-12T14:23:44.988427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\n\n# Load both models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/xception_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\n\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\ndef combined_predict_skin_cancer(img):\n    # Preprocess the image for both models\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n    \n    # Make predictions\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n    \n    # Apply weights to each model's predictions\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n    \n    # Combine weighted predictions\n    combined_predictions = (weighted_predictions1 + weighted_predictions2) / 2\n    \n    # Get the predicted class index\n    predicted_class_index = np.argmax(combined_predictions)\n    \n    # Get the predicted class name\n    predicted_class = class_names[predicted_class_index]\n    \n    # Get the confidence score as a percentage\n    confidence = combined_predictions[predicted_class_index] * 100\n    \n    # Convert all probabilities to percentages\n    probabilities_percentage = combined_predictions * 100\n    \n    return predicted_class, confidence, probabilities_percentage\n\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Main prediction function\ndef predict_from_url(img_url):\n    try:\n        # Load the image from URL\n        response = requests.get(img_url)\n        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n        \n        # Perform prediction\n        predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(image)\n        \n        print(f\"Predicted class: {predicted_class}\")\n        print(f\"Confidence: {confidence:.2f}%\")\n        print(\"\\nProbabilities for all classes:\")\n        for class_name, probability in zip(class_names, all_probabilities):\n            print(f\"{class_name}: {probability:.2f}%\")\n        \n        # Display the prediction as a bar chart\n        display_prediction(all_probabilities, class_names)\n        \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Example usage\nimg_url = input(\"Enter the URL of the image: \")\npredict_from_url(img_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:49:33.886357Z","iopub.execute_input":"2024-09-12T14:49:33.886777Z","iopub.status.idle":"2024-09-12T14:49:46.365473Z","shell.execute_reply.started":"2024-09-12T14:49:33.886739Z","shell.execute_reply":"2024-09-12T14:49:46.364364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\n\n# Load both models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/xception_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\n\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\ndef combined_predict_skin_cancer(img):\n    # Preprocess the image for both models\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n    \n    # Make predictions\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n    \n    # Apply weights to each model's predictions\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n    \n    # Combine weighted predictions\n    combined_predictions = weighted_predictions1 + weighted_predictions2\n    \n    # Normalize the combined predictions to ensure they sum to 1\n    combined_predictions = combined_predictions / np.sum(combined_predictions)\n    \n    # Get the predicted class index\n    predicted_class_index = np.argmax(combined_predictions)\n    \n    # Get the predicted class name\n    predicted_class = class_names[predicted_class_index]\n    \n    # Get the confidence score as a percentage\n    confidence = combined_predictions[predicted_class_index] * 100\n    \n    # Convert all probabilities to percentages\n    probabilities_percentage = combined_predictions * 100\n    \n    return predicted_class, confidence, probabilities_percentage\n\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Main prediction function\ndef predict_from_url(img_url):\n    try:\n        # Load the image from URL\n        response = requests.get(img_url)\n        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n        \n        # Perform prediction\n        predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(image)\n        \n        print(f\"Predicted class: {predicted_class}\")\n        print(f\"Confidence: {confidence:.2f}%\")\n        print(\"\\nProbabilities for all classes:\")\n        for class_name, probability in zip(class_names, all_probabilities):\n            print(f\"{class_name}: {probability:.2f}%\")\n        \n        # Display the prediction as a bar chart\n        display_prediction(all_probabilities, class_names)\n        \n        # Print total probability\n        print(f\"\\nTotal probability: {np.sum(all_probabilities):.2f}%\")\n        \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Example usage\nimg_url = input(\"Enter the URL of the image: \")\npredict_from_url(img_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T04:00:09.551725Z","iopub.execute_input":"2024-09-13T04:00:09.55215Z","iopub.status.idle":"2024-09-13T04:10:07.289514Z","shell.execute_reply.started":"2024-09-13T04:00:09.552109Z","shell.execute_reply":"2024-09-13T04:10:07.28777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install ipywidgets\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T04:12:32.805876Z","iopub.execute_input":"2024-09-13T04:12:32.80636Z","iopub.status.idle":"2024-09-13T04:12:50.891286Z","shell.execute_reply.started":"2024-09-13T04:12:32.806305Z","shell.execute_reply":"2024-09-13T04:12:50.889799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load both models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/2/xception_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\n\n# Preprocessing functions for both models\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\n# Combined prediction function\ndef combined_predict_skin_cancer(img):\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n\n    combined_predictions = weighted_predictions1 + weighted_predictions2\n    combined_predictions = combined_predictions / np.sum(combined_predictions)\n\n    predicted_class_index = np.argmax(combined_predictions)\n    predicted_class = class_names[predicted_class_index]\n    confidence = combined_predictions[predicted_class_index] * 100\n    probabilities_percentage = combined_predictions * 100\n\n    return predicted_class, confidence, probabilities_percentage\n\n# Display bar chart for predictions\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Display the loaded image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Prediction handler function\ndef handle_prediction(img):\n    display_image(img)\n    predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(img)\n\n    print(f\"Predicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, probability in zip(class_names, all_probabilities):\n        print(f\"{class_name}: {probability:.2f}%\")\n\n    display_prediction(all_probabilities, class_names)\n\n# Load image from URL\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    return img\n\n# Load image from file\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).convert(\"RGB\")\n    return img\n\n# Widgets for input\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_content = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_content)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link buttons to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:54:07.199874Z","iopub.execute_input":"2024-09-14T16:54:07.200321Z","iopub.status.idle":"2024-09-14T16:54:28.662945Z","shell.execute_reply.started":"2024-09-14T16:54:07.200279Z","shell.execute_reply":"2024-09-14T16:54:28.661639Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Text(value='', description='Image URL:', placeholder='Enter the URL of the image'), FileUpload(","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bf91e9b4de24b00905da8f3cafbc3cc"}},"metadata":{}}]},{"cell_type":"markdown","source":"# 3 model Ensemble ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load all three models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/3/xception_model_v6.h5\")\nmodel3 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/3/mobilenetv2_model_v6.h5\")  # Replace with the actual path\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.34])\nweights_model2 = np.array([0.2, 0.2, 0.2, 0.2, 0.33])\nweights_model3 = np.array([0.2, 0.2, 0.2, 0.2, 0.33])\n\n# Preprocessing functions for all models\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\n# Use the same preprocessing as model2 for model3\npreprocess_image_model3 = preprocess_image_model2\n\n# Combined prediction function\ndef combined_predict_skin_cancer(img):\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n    processed_image3 = preprocess_image_model3(img)\n\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n    predictions3 = model3.predict(processed_image3)[0]\n\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n    weighted_predictions3 = predictions3 * weights_model3\n\n    combined_predictions = weighted_predictions1 + weighted_predictions2 + weighted_predictions3\n    combined_predictions = combined_predictions / np.sum(combined_predictions)\n\n    predicted_class_index = np.argmax(combined_predictions)\n    predicted_class = class_names[predicted_class_index]\n    confidence = combined_predictions[predicted_class_index] * 100\n    probabilities_percentage = combined_predictions * 100\n\n    return predicted_class, confidence, probabilities_percentage\n\n# Display bar chart for predictions\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Display the loaded image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Prediction handler function\ndef handle_prediction(img):\n    display_image(img)\n    predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(img)\n\n    print(f\"Predicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, probability in zip(class_names, all_probabilities):\n        print(f\"{class_name}: {probability:.2f}%\")\n\n    display_prediction(all_probabilities, class_names)\n\n# Load image from URL\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    return img\n\n# Load image from file\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).convert(\"RGB\")\n    return img\n\n# Widgets for input\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_content = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_content)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link buttons to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))","metadata":{"execution":{"iopub.status.busy":"2024-09-14T17:45:22.891002Z","iopub.execute_input":"2024-09-14T17:45:22.891478Z","iopub.status.idle":"2024-09-14T17:45:29.306578Z","shell.execute_reply.started":"2024-09-14T17:45:22.891433Z","shell.execute_reply":"2024-09-14T17:45:29.305416Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Text(value='', description='Image URL:', placeholder='Enter the URL of the image'), FileUpload(","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e33d3c4d8a495c810464cb9978a2a6"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib import colormaps\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import load_model\nfrom IPython.display import Image as imgdisp, display\nimport ipywidgets as widgets\nfrom IPython.display import clear_output\nimport requests\nfrom io import BytesIO\n\n# Load the pre-trained model\nmodel = load_model('/kaggle/input/isic6k/keras/default/3/mobilenetv2_model_v6.h5')\n\n# Function to preprocess image\ndef preprocess_image(img_array, size=(224, 224)):\n    img = Image.fromarray(img_array)\n    img = img.resize(size, Image.LANCZOS)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array.astype('float32') / 255\n\n# Function to resize image keeping aspect ratio with fixed height\ndef resize_image_aspect_ratio(img_array, height):\n    img = Image.fromarray(img_array)\n    width, original_height = img.size\n    aspect_ratio = width / original_height\n    new_width = int(height * aspect_ratio)\n    img = img.resize((new_width, height), Image.LANCZOS)\n    return np.array(img), (new_width, height)\n\n# Function to generate Grad-CAM heatmap\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        model.inputs, \n        [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    \n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    \n    return heatmap.numpy()\n\n# Function to generate heatmap from the image\ndef generate_heatmap(img_array, last_conv_layer_name):\n    img_array, _ = resize_image_aspect_ratio(img_array, 224)\n    img_array = preprocess_image(img_array)\n    model.layers[-1].activation = None  # Remove last layer's softmax\n    return make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# Function to save and display Grad-CAM image\ndef save_and_display_gradcam(img_array, heatmap, cam_path=\"/kaggle/working/cam.jpg\", alpha=0.4):\n    img, (new_width, height) = resize_image_aspect_ratio(img_array, 224)\n    img = Image.fromarray(img)\n    \n    heatmap = np.uint8(255 * heatmap)\n    jet = colormaps.get_cmap(\"jet\")\n    jet_heatmap = jet(np.arange(256))[:, :3][heatmap]\n    \n    jet_heatmap = Image.fromarray(np.uint8(jet_heatmap * 255))  # Convert to 8-bit\n    jet_heatmap = jet_heatmap.resize((new_width, height))\n    jet_heatmap = np.array(jet_heatmap)\n    \n    superimposed_img = jet_heatmap * alpha + np.array(img)\n    superimposed_img = Image.fromarray(np.uint8(superimposed_img))\n    superimposed_img.save(cam_path)\n\n    display(imgdisp(cam_path))\n\n# Function to load image from URL\ndef load_image_from_url(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    return np.array(img)\n\n# Function to load image from file upload\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content))\n    return np.array(img)\n\n# Function to display the input image\ndef display_image(img_array, height=224):\n    img, (new_width, _) = resize_image_aspect_ratio(img_array, height)\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img_array = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_content = list(file_upload.value.values())[0]['content']\n            img_array = load_image_from_file(file_content)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        \n        display_image(img_array)\n        heatmap = generate_heatmap(img_array, \"block_16_depthwise\")\n        save_and_display_gradcam(img_array, heatmap)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T17:49:51.927784Z","iopub.execute_input":"2024-09-14T17:49:51.928276Z","iopub.status.idle":"2024-09-14T17:49:53.605428Z","shell.execute_reply.started":"2024-09-14T17:49:51.928231Z","shell.execute_reply":"2024-09-14T17:49:53.603968Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Text(value='', description='Image URL:', placeholder='Enter the URL of the image'), FileUpload(","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c3ec2dd1d245f5a7594771393d9618"}},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nfrom matplotlib import colormaps\nfrom IPython.display import Image as imgdisp\n\n# Load all three models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/3/xception_model_v6.h5\")\nmodel3 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/3/mobilenetv2_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.34])\nweights_model2 = np.array([0.2, 0.2, 0.2, 0.2, 0.33])\nweights_model3 = np.array([0.2, 0.2, 0.2, 0.2, 0.33])\n\n# Preprocessing functions\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\npreprocess_image_model3 = preprocess_image_model2\n\n# Combined prediction function\ndef combined_predict_skin_cancer(img):\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n    processed_image3 = preprocess_image_model3(img)\n\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n    predictions3 = model3.predict(processed_image3)[0]\n\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n    weighted_predictions3 = predictions3 * weights_model3\n\n    combined_predictions = weighted_predictions1 + weighted_predictions2 + weighted_predictions3\n    combined_predictions = combined_predictions / np.sum(combined_predictions)\n\n    predicted_class_index = np.argmax(combined_predictions)\n    predicted_class = class_names[predicted_class_index]\n    confidence = combined_predictions[predicted_class_index] * 100\n    probabilities_percentage = combined_predictions * 100\n\n    return predicted_class, confidence, probabilities_percentage\n\n# Display bar chart for predictions\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Display the loaded image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Grad-CAM functions\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        model.inputs, \n        [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    \n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    \n    return heatmap.numpy()\n\ndef generate_heatmap(img_array, last_conv_layer_name):\n    img_array = preprocess_image_model3(Image.fromarray(img_array))\n    model3.layers[-1].activation = None  # Remove last layer's softmax\n    return make_gradcam_heatmap(img_array, model3, last_conv_layer_name)\n\ndef save_and_display_gradcam(img_array, heatmap, cam_path=\"/kaggle/working/cam.jpg\", alpha=0.4):\n    # Convert img_array to a PIL image\n    img = Image.fromarray(img_array)\n\n    # Resize img_array height to 224 pixels and adjust width to maintain aspect ratio\n    width, height = img.size\n    new_height = 224\n    new_width = int((new_height / height) * width)\n    img = img.resize((new_width, new_height))\n    img_array = np.array(img)\n\n    # Resize heatmap to match img_array\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = Image.fromarray(heatmap).resize((new_width, new_height))\n    heatmap = np.array(heatmap)\n\n    # Apply colormap to heatmap\n    jet = colormaps.get_cmap(\"jet\")\n    jet_heatmap = jet(heatmap)[:, :, :3]\n    jet_heatmap = np.uint8(jet_heatmap * 255)\n\n    # Superimpose heatmap on the original image\n    superimposed_img = jet_heatmap * alpha + img_array * (1 - alpha)\n    superimposed_img = np.uint8(superimposed_img)\n    \n    # Save and display the superimposed image\n    superimposed_img = Image.fromarray(superimposed_img)\n    superimposed_img.save(cam_path)\n    \n    display(Image.open(cam_path))\n# Load image functions\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).convert(\"RGB\")\n    return img\n\n# Prediction handler function\ndef handle_prediction(img):\n    display_image(img)\n    predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(img)\n\n    print(f\"Predicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, probability in zip(class_names, all_probabilities):\n        print(f\"{class_name}: {probability:.2f}%\")\n\n    display_prediction(all_probabilities, class_names)\n\n    # Only generate and display Grad-CAM if the predicted class is not \"No_cancer\"\n    if predicted_class != \"No_cancer\":\n        img_array = np.array(img)\n        heatmap = generate_heatmap(img_array, \"block_16_depthwise\")\n        print(\"\\nGrad-CAM Heatmap:\")\n        save_and_display_gradcam(img_array, heatmap)\n    else:\n        print(\"\\nGrad-CAM not displayed for 'No_cancer' prediction.\")\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_content = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_content)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Link buttons to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:06:46.741241Z","iopub.execute_input":"2024-09-14T18:06:46.741801Z","iopub.status.idle":"2024-09-14T18:06:52.797093Z","shell.execute_reply.started":"2024-09-14T18:06:46.741751Z","shell.execute_reply":"2024-09-14T18:06:52.795857Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Text(value='', description='Image URL:', placeholder='Enter the URL of the image'), FileUpload(","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a884983ae2b4394a4cda4f28c80e4dc"}},"metadata":{}}]}]}
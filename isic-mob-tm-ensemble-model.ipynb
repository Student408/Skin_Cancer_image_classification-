{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9339772,"sourceType":"datasetVersion","datasetId":5660034},{"sourceId":109861,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":91923,"modelId":116131},{"sourceId":109862,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":91665,"modelId":115884},{"sourceId":111705,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":93615,"modelId":117825},{"sourceId":112336,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":93615,"modelId":117825},{"sourceId":112396,"sourceType":"modelInstanceVersion","modelInstanceId":93615,"modelId":117825}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lokotwist/isic-mob-tm-ensemble-model?scriptVersionId=196445572\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n\n\n# Normalize test data for this model\nx_valid = feats_test.astype('float32') / 255\ny_valid = to_categorical(labels_test, 5)\n\n# Load the model\nmodel = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set\nBS = 10\npred_Y = model.predict(x_valid, batch_size=BS, verbose=True)\n\n# Convert predictions and true labels to class indices\npred = np.argmax(pred_Y, axis=1)\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=class_names)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:27:40.516326Z","iopub.execute_input":"2024-09-09T16:27:40.516776Z","iopub.status.idle":"2024-09-09T16:27:56.683049Z","shell.execute_reply.started":"2024-09-09T16:27:40.516737Z","shell.execute_reply":"2024-09-09T16:27:56.682211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, pred)\nprint(f\"Model Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:28:04.186661Z","iopub.execute_input":"2024-09-09T16:28:04.187768Z","iopub.status.idle":"2024-09-09T16:28:04.193777Z","shell.execute_reply.started":"2024-09-09T16:28:04.187723Z","shell.execute_reply":"2024-09-09T16:28:04.192781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate the classification report\nreport = classification_report(rounded_labels, pred, target_names=['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer'])\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:28:10.978876Z","iopub.execute_input":"2024-09-09T16:28:10.979566Z","iopub.status.idle":"2024-09-09T16:28:10.995085Z","shell.execute_reply.started":"2024-09-09T16:28:10.979524Z","shell.execute_reply":"2024-09-09T16:28:10.993942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\n\n\n\n# Normalize test data for this model (Teachable Machine normalization)\nx_valid = (feats_test.astype('float32') / 127.5) - 1\ny_valid = to_categorical(labels_test, 5)\n\n# Load the model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set\nBS = 10\npred_Y = model2.predict(x_valid, batch_size=BS, verbose=True)\n\n# Convert predictions and true labels to class indices\npred = np.argmax(pred_Y, axis=1)\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=class_names)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T13:52:27.677708Z","iopub.execute_input":"2024-09-12T13:52:27.678784Z","iopub.status.idle":"2024-09-12T13:52:29.043689Z","shell.execute_reply.started":"2024-09-12T13:52:27.678731Z","shell.execute_reply":"2024-09-12T13:52:29.042219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize the test data using Teachable Machine normalization\nx_valid = (feats_test.astype('float32') / 127.5) - 1\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for the test set\npred_Y = model2.predict(x_valid, batch_size=10, verbose=True)\n\n# Convert predictions and true labels to class indices\npred = np.argmax(pred_Y, axis=1)\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Confusion Matrix Function\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, \"{:.2f}\".format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, pred)\n\n# Class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Confusion Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:29:34.358113Z","iopub.execute_input":"2024-09-09T16:29:34.358891Z","iopub.status.idle":"2024-09-09T16:29:49.631457Z","shell.execute_reply.started":"2024-09-09T16:29:34.358851Z","shell.execute_reply":"2024-09-09T16:29:49.630533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate the classification report\nreport = classification_report(rounded_labels, pred, target_names=['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer'])\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:30:23.996081Z","iopub.execute_input":"2024-09-09T16:30:23.996735Z","iopub.status.idle":"2024-09-09T16:30:24.011845Z","shell.execute_reply.started":"2024-09-09T16:30:23.996693Z","shell.execute_reply":"2024-09-09T16:30:24.010976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions (e.g., by averaging the predicted probabilities)\ncombined_pred_Y = (pred_Y_model1 + pred_Y_model2) / 2\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:19:57.798289Z","iopub.execute_input":"2024-09-09T15:19:57.799629Z","iopub.status.idle":"2024-09-09T15:22:46.233324Z","shell.execute_reply.started":"2024-09-09T15:19:57.799576Z","shell.execute_reply":"2024-09-09T15:22:46.232021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.65 * pred_Y_model1) + (0.35 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix with Weighted Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:32:01.620748Z","iopub.execute_input":"2024-09-09T15:32:01.621449Z","iopub.status.idle":"2024-09-09T15:32:31.520826Z","shell.execute_reply.started":"2024-09-09T15:32:01.621402Z","shell.execute_reply":"2024-09-09T15:32:31.519888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.6 * pred_Y_model1) + (0.4 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix with Weighted Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:33:02.85464Z","iopub.execute_input":"2024-09-09T15:33:02.855049Z","iopub.status.idle":"2024-09-09T15:33:32.39003Z","shell.execute_reply.started":"2024-09-09T15:33:02.85501Z","shell.execute_reply":"2024-09-09T15:33:32.389037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.68 * pred_Y_model1) + (0.32 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Define class names for this dataset\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=class_names, title='Combined Confusion Matrix with Weighted Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:06:26.279045Z","iopub.execute_input":"2024-09-09T16:06:26.279807Z","iopub.status.idle":"2024-09-09T16:06:56.295972Z","shell.execute_reply.started":"2024-09-09T16:06:26.27977Z","shell.execute_reply":"2024-09-09T16:06:56.29495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.68 * pred_Y_model1) + (0.32 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\nfrom sklearn.metrics import classification_report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:07:07.069521Z","iopub.execute_input":"2024-09-09T16:07:07.069898Z","iopub.status.idle":"2024-09-09T16:07:37.149247Z","shell.execute_reply.started":"2024-09-09T16:07:07.069864Z","shell.execute_reply":"2024-09-09T16:07:37.148162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Combine the predictions with 60% weight to model1 and 40% weight to model2\ncombined_pred_Y = (0.9 * pred_Y_model1) + (0.1 * pred_Y_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\nfrom sklearn.metrics import classification_report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:50:18.033535Z","iopub.execute_input":"2024-09-09T15:50:18.033856Z","iopub.status.idle":"2024-09-09T15:50:47.976354Z","shell.execute_reply.started":"2024-09-09T15:50:18.033822Z","shell.execute_reply":"2024-09-09T15:50:47.975405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.75, 0.8, 0.5, 0.72])  # Model 1 precision\nweights_model2 = np.array([0.4, 0.25, 0.2, 0.5, 0.28])  # Model 2 precision\n\n# Ensure weights are applied to each prediction\ncombined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n\n# Normalize the combined predictions (optional, but usually recommended)\ncombined_pred_Y /= (weights_model1 + weights_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:58:54.980466Z","iopub.execute_input":"2024-09-09T16:58:54.981156Z","iopub.status.idle":"2024-09-09T16:58:55.000174Z","shell.execute_reply.started":"2024-09-09T16:58:54.981117Z","shell.execute_reply":"2024-09-09T16:58:54.99933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Load the test data\nfeats_test = np.load(\"/kaggle/input/isic19-npy/6k_feats_test.npy\")\nlabels_test = np.load(\"/kaggle/input/isic19-npy/6k_labels_test.npy\")\n\n# Normalize test data for the first model\nx_valid_model1 = feats_test.astype('float32') / 255\n\n# Normalize test data for the second model using Teachable Machine normalization\nx_valid_model2 = (feats_test.astype('float32') / 127.5) - 1\n\n# One-hot encode the labels\ny_valid = tf.keras.utils.to_categorical(labels_test, 5)\n\n# Load the first model\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_4k_81/keras/default/3/isic4k_model_v2.h5\")\n\n# Predict the labels for test set using the first model\npred_Y_model1 = model1.predict(x_valid_model1, batch_size=10, verbose=True)\n\n# Load the second model\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Predict the labels for test set using the second model\npred_Y_model2 = model2.predict(x_valid_model2, batch_size=10, verbose=True)\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.75, 0.8, 0.5, 0.72])  # Model 1 precision\nweights_model2 = np.array([0.4, 0.25, 0.2, 0.5, 0.28])  # Model 2 precision\n\n# Ensure weights are applied to each prediction\ncombined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n\n# Normalize the combined predictions (optional, but usually recommended)\ncombined_pred_Y /= (weights_model1 + weights_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Function to plot the confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=target_names, title='Combined Confusion Matrix with Class-Specific Weights')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:42.541571Z","iopub.execute_input":"2024-09-12T14:05:42.542065Z","iopub.status.idle":"2024-09-12T14:06:07.04249Z","shell.execute_reply.started":"2024-09-12T14:05:42.542018Z","shell.execute_reply":"2024-09-12T14:06:07.040203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.75, 0.8, 0.5, 0.72])  # Model 1 precision\nweights_model2 = np.array([0.4, 0.25, 0.2, 0.5, 0.28])  # Model 2 precision\n\n# Ensure weights are applied to each prediction\ncombined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n\n# Normalize the combined predictions (optional, but usually recommended)\ncombined_pred_Y /= (weights_model1 + weights_model2)\n\n# Convert combined predictions to class indices\ncombined_pred = np.argmax(combined_pred_Y, axis=1)\n\n# Convert true labels to class indices\nrounded_labels = np.argmax(y_valid, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(rounded_labels, combined_pred)\nprint(f'Combined Model Accuracy: {accuracy:.4f}')\n\n# Show a nicely formatted classification report\ntarget_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\nprint(classification_report(rounded_labels, combined_pred, target_names=target_names))\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(rounded_labels, combined_pred)\n\n# Function to plot the confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 8))\nplot_confusion_matrix(confusion_mtx, classes=target_names, title='Combined Confusion Matrix with Class-Specific Weights')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:17:16.914982Z","iopub.execute_input":"2024-09-09T17:17:16.915903Z","iopub.status.idle":"2024-09-09T17:17:17.361532Z","shell.execute_reply.started":"2024-09-09T17:17:16.915859Z","shell.execute_reply":"2024-09-09T17:17:17.360527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])  # Model 1 precision\nweights_model2 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])  # Model 2 precision\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n        image_model1 = image_array.astype('float32') / 255\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Get the top 2 predicted classes and their confidence\n    top_2_indices = np.argsort(combined_pred_Y[0])[-2:][::-1]\n    \n    # Get the top 2 confidence scores\n    top_2_confidences = combined_pred_Y[0][top_2_indices] * 100\n    \n    # Display the results\n    print(f\"Top 1 Predicted Class: {class_names[top_2_indices[0]]}\")\n    print(f\"Confidence: {top_2_confidences[0]:.2f}%\")\n    print(f\"Top 2 Predicted Class: {class_names[top_2_indices[1]]}\")\n    print(f\"Confidence: {top_2_confidences[1]:.2f}%\")\n    \n    # Plot the image\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Top 1: {class_names[top_2_indices[0]]} ({top_2_confidences[0]:.2f}%)\\n\"\n              f\"Top 2: {class_names[top_2_indices[1]]} ({top_2_confidences[1]:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T13:41:34.897377Z","iopub.execute_input":"2024-09-12T13:41:34.897764Z","iopub.status.idle":"2024-09-12T13:42:26.738737Z","shell.execute_reply.started":"2024-09-12T13:41:34.897721Z","shell.execute_reply":"2024-09-12T13:42:26.737567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load the model\n# model = load_model('/kaggle/working/isic4k50_model_v5.h5')\nmodel = load_model('/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5')\n\n# Dictionary for class labels\nclass_dict = {\n    0: \"Basal_Cell_Carcinoma\",\n    1: \"Melanoma\",\n    2: \"Nevus\",\n    3: \"Benign_keratosis\",\n    4: \"No_cancer\"\n}\n\n# Helper function to preprocess image and make predictions\ndef process_image(img, model):\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255   \n    preds = model.predict(img_array)[0]\n    return preds\n\n# Function to process image from URL or File\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).resize((224, 224))\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).resize((224, 224))\n    return img\n\n# Function to display prediction as a bar chart with transparent background\ndef display_prediction(preds, class_dict):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    classes = list(class_dict.values())\n    confidences = preds * 100\n    \n    ax.barh(classes, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Function to handle the prediction process\ndef handle_prediction(img, model, class_dict):\n    preds = process_image(img, model)\n    display_image(img)\n    display_prediction(preds, class_dict)\n    pred_class = np.argmax(preds)\n    confidence = preds[pred_class] * 100\n    print(f\"\\nPredicted class: {class_dict[pred_class]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n\n# Function to display the input image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_path = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_path)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img, model, class_dict)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T15:32:22.766068Z","iopub.execute_input":"2024-09-12T15:32:22.766544Z","iopub.status.idle":"2024-09-12T15:32:24.258703Z","shell.execute_reply.started":"2024-09-12T15:32:22.766499Z","shell.execute_reply":"2024-09-12T15:32:24.25731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load the model\n# model = load_model('/kaggle/working/isic4k50_model_v5.h5')\nmodel = load_model('/kaggle/input/isic6k/keras/default/2/mobilenetv2_model_v7.h5')\n\n# Dictionary for class labels\nclass_dict = {\n    0: \"Basal_Cell_Carcinoma\",\n    1: \"Melanoma\",\n    2: \"Nevus\",\n    3: \"Benign_keratosis\",\n    4: \"No_cancer\"\n}\n\n# Helper function to preprocess image and make predictions\ndef process_image(img, model):\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255   \n    preds = model.predict(img_array)[0]\n    return preds\n\n# Function to process image from URL or File\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).resize((224, 224))\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).resize((224, 224))\n    return img\n\n# Function to display prediction as a bar chart with transparent background\ndef display_prediction(preds, class_dict):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    classes = list(class_dict.values())\n    confidences = preds * 100\n    \n    ax.barh(classes, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Function to handle the prediction process\ndef handle_prediction(img, model, class_dict):\n    preds = process_image(img, model)\n    display_image(img)\n    display_prediction(preds, class_dict)\n    pred_class = np.argmax(preds)\n    confidence = preds[pred_class] * 100\n    print(f\"\\nPredicted class: {class_dict[pred_class]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n\n# Function to display the input image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_path = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_path)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img, model, class_dict)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T15:31:29.440166Z","iopub.execute_input":"2024-09-12T15:31:29.441164Z","iopub.status.idle":"2024-09-12T15:31:31.09244Z","shell.execute_reply.started":"2024-09-12T15:31:29.441093Z","shell.execute_reply":"2024-09-12T15:31:31.091284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load the model\n# model = load_model('/kaggle/working/isic4k50_model_v5.h5')\nmodel = load_model('/kaggle/input/isic6k/keras/default/1/xception_model_v6.h5')\n\n# Dictionary for class labels\nclass_dict = {\n    0: \"Basal_Cell_Carcinoma\",\n    1: \"Melanoma\",\n    2: \"Nevus\",\n    3: \"Benign_keratosis\",\n    4: \"No_cancer\"\n}\n\n# Helper function to preprocess image and make predictions\ndef process_image(img, model):\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    preds = model.predict(img_array)[0]\n    return preds\n\n# Function to process image from URL or File\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).resize((224, 224))\n    return img\n\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).resize((224, 224))\n    return img\n\n# Function to display prediction as a bar chart with transparent background\ndef display_prediction(preds, class_dict):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    classes = list(class_dict.values())\n    confidences = preds * 100\n    \n    ax.barh(classes, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Function to handle the prediction process\ndef handle_prediction(img, model, class_dict):\n    preds = process_image(img, model)\n    display_image(img)\n    display_prediction(preds, class_dict)\n    pred_class = np.argmax(preds)\n    confidence = preds[pred_class] * 100\n    print(f\"\\nPredicted class: {class_dict[pred_class]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n\n# Function to display the input image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Widgets\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_path = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_path)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img, model, class_dict)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link button clicks to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T15:32:40.275767Z","iopub.execute_input":"2024-09-12T15:32:40.276273Z","iopub.status.idle":"2024-09-12T15:32:42.726201Z","shell.execute_reply.started":"2024-09-12T15:32:40.276214Z","shell.execute_reply":"2024-09-12T15:32:42.724894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\n\n# Load the model\nmodel = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\ndef preprocess_image(img):\n    # Resize the image to (224, 224) and crop from the center if needed\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    \n    # Convert to array\n    img_array = np.asarray(img)\n    \n    # Normalize the image\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    \n    # Expand dimensions to create batch\n    img_array = np.expand_dims(img_array, axis=0)\n    \n    return img_array\n\ndef predict_skin_cancer(img):\n    # Preprocess the image\n    processed_image = preprocess_image(img)\n    \n    # Make prediction\n    predictions = model.predict(processed_image)\n    \n    # Get the predicted class index\n    predicted_class_index = np.argmax(predictions[0])\n    \n    # Get the predicted class name\n    predicted_class = class_names[predicted_class_index]\n    \n    # Get the confidence score as a percentage\n    confidence = predictions[0][predicted_class_index] * 100\n    \n    # Convert all probabilities to percentages\n    probabilities_percentage = predictions[0] * 100\n    \n    return predicted_class, confidence, probabilities_percentage\n\n# Prompt user for image URL\nimg_url = input(\"Enter the URL of the image: \")\n\ntry:\n    # Load the image from URL\n    response = requests.get(img_url)\n    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    \n    # Perform prediction\n    predicted_class, confidence, all_probabilities = predict_skin_cancer(image)\n\n    print(f\"Predicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, probability in zip(class_names, all_probabilities):\n        print(f\"{class_name}: {probability:.2f}%\")\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:58:51.964898Z","iopub.execute_input":"2024-09-12T14:58:51.965488Z","iopub.status.idle":"2024-09-12T14:58:56.526352Z","shell.execute_reply.started":"2024-09-12T14:58:51.965442Z","shell.execute_reply":"2024-09-12T14:58:56.525211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.4, 0.4, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.6, 0.6, 0.4, 0.5])\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n        image_model1 = image_array.astype('float32') / 255\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Get the predicted class and confidence\n    predicted_class_idx = np.argmax(combined_pred_Y)\n    confidence = combined_pred_Y[0][predicted_class_idx] * 100\n    \n    # Display the results\n    print(f\"Predicted Class: {class_names[predicted_class_idx]}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    \n    # Plot the image\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:12:40.084625Z","iopub.execute_input":"2024-09-12T14:12:40.085575Z","iopub.status.idle":"2024-09-12T14:13:00.942967Z","shell.execute_reply.started":"2024-09-12T14:12:40.08552Z","shell.execute_reply":"2024-09-12T14:13:00.941799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\nweights_model2 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/mobilenetv2_model_v6.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n        image_model1 = image_array.astype('float32') / 255\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Display the prediction percentages for all classes\n    print(\"Class prediction percentages:\")\n    for i, class_name in enumerate(class_names):\n        confidence = combined_pred_Y[0][i] * 100\n        print(f\"{class_name}: {confidence:.2f}%\")\n    \n    # Get the predicted class and confidence for the top prediction\n    predicted_class_idx = np.argmax(combined_pred_Y)\n    confidence = combined_pred_Y[0][predicted_class_idx] * 100\n    \n    # Plot the image with the predicted class and confidence\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:20:23.962105Z","iopub.execute_input":"2024-09-12T14:20:23.962709Z","iopub.status.idle":"2024-09-12T14:20:35.203581Z","shell.execute_reply.started":"2024-09-12T14:20:23.962655Z","shell.execute_reply":"2024-09-12T14:20:35.2022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom urllib import request\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Predefined class names\nclass_names = ['BCC', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\nweights_model2 = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\n\n# Load the models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\n\n# Function to fetch and preprocess image\ndef preprocess_image(image_url, target_size=(224, 224)):\n    with request.urlopen(image_url) as url:\n        image = Image.open(url).resize(target_size)\n        image_array = np.array(image)\n#         image_model1 = image_array.astype('float32') / 255\n        image_model1 = (image_array.astype('float32') / 127.5) - 1\n        image_model2 = (image_array.astype('float32') / 127.5) - 1\n        return image_model1, image_model2\n\n# Function to predict class of the image\ndef predict_image_class(image_url):\n    image_model1, image_model2 = preprocess_image(image_url)\n    image_model1 = np.expand_dims(image_model1, axis=0)\n    image_model2 = np.expand_dims(image_model2, axis=0)\n    \n    # Predict using both models\n    pred_Y_model1 = model1.predict(image_model1)\n    pred_Y_model2 = model2.predict(image_model2)\n    \n    # Combine the predictions with class-specific weights\n    combined_pred_Y = (weights_model1 * pred_Y_model1) + (weights_model2 * pred_Y_model2)\n    combined_pred_Y /= (weights_model1 + weights_model2)\n    \n    # Display the prediction percentages for all classes\n    print(\"Class prediction percentages:\")\n    for i, class_name in enumerate(class_names):\n        confidence = combined_pred_Y[0][i] * 100  # Convert to percentage\n        print(f\"{class_name}: {confidence:.2f}%\")\n    \n    # Get the predicted class and confidence for the top prediction\n    predicted_class_idx = np.argmax(combined_pred_Y)\n    confidence = combined_pred_Y[0][predicted_class_idx] * 100  # Convert to percentage\n    \n    # Plot the image with the predicted class and confidence\n    plt.imshow(np.array(Image.open(request.urlopen(image_url))))\n    plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\")\n    plt.axis('off')\n    plt.show()\n\n# URL prompt for the user to enter an image URL\nimage_url = input(\"Enter the image URL: \")\npredict_image_class(image_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:23:34.925111Z","iopub.execute_input":"2024-09-12T14:23:34.926422Z","iopub.status.idle":"2024-09-12T14:23:44.989744Z","shell.execute_reply.started":"2024-09-12T14:23:34.92635Z","shell.execute_reply":"2024-09-12T14:23:44.988427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\n\n# Load both models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/xception_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\n\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\ndef combined_predict_skin_cancer(img):\n    # Preprocess the image for both models\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n    \n    # Make predictions\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n    \n    # Apply weights to each model's predictions\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n    \n    # Combine weighted predictions\n    combined_predictions = (weighted_predictions1 + weighted_predictions2) / 2\n    \n    # Get the predicted class index\n    predicted_class_index = np.argmax(combined_predictions)\n    \n    # Get the predicted class name\n    predicted_class = class_names[predicted_class_index]\n    \n    # Get the confidence score as a percentage\n    confidence = combined_predictions[predicted_class_index] * 100\n    \n    # Convert all probabilities to percentages\n    probabilities_percentage = combined_predictions * 100\n    \n    return predicted_class, confidence, probabilities_percentage\n\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Main prediction function\ndef predict_from_url(img_url):\n    try:\n        # Load the image from URL\n        response = requests.get(img_url)\n        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n        \n        # Perform prediction\n        predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(image)\n        \n        print(f\"Predicted class: {predicted_class}\")\n        print(f\"Confidence: {confidence:.2f}%\")\n        print(\"\\nProbabilities for all classes:\")\n        for class_name, probability in zip(class_names, all_probabilities):\n            print(f\"{class_name}: {probability:.2f}%\")\n        \n        # Display the prediction as a bar chart\n        display_prediction(all_probabilities, class_names)\n        \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Example usage\nimg_url = input(\"Enter the URL of the image: \")\npredict_from_url(img_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:49:33.886357Z","iopub.execute_input":"2024-09-12T14:49:33.886777Z","iopub.status.idle":"2024-09-12T14:49:46.365473Z","shell.execute_reply.started":"2024-09-12T14:49:33.886739Z","shell.execute_reply":"2024-09-12T14:49:46.364364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\n\n# Load both models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/1/xception_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\n\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\ndef combined_predict_skin_cancer(img):\n    # Preprocess the image for both models\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n    \n    # Make predictions\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n    \n    # Apply weights to each model's predictions\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n    \n    # Combine weighted predictions\n    combined_predictions = weighted_predictions1 + weighted_predictions2\n    \n    # Normalize the combined predictions to ensure they sum to 1\n    combined_predictions = combined_predictions / np.sum(combined_predictions)\n    \n    # Get the predicted class index\n    predicted_class_index = np.argmax(combined_predictions)\n    \n    # Get the predicted class name\n    predicted_class = class_names[predicted_class_index]\n    \n    # Get the confidence score as a percentage\n    confidence = combined_predictions[predicted_class_index] * 100\n    \n    # Convert all probabilities to percentages\n    probabilities_percentage = combined_predictions * 100\n    \n    return predicted_class, confidence, probabilities_percentage\n\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Main prediction function\ndef predict_from_url(img_url):\n    try:\n        # Load the image from URL\n        response = requests.get(img_url)\n        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n        \n        # Perform prediction\n        predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(image)\n        \n        print(f\"Predicted class: {predicted_class}\")\n        print(f\"Confidence: {confidence:.2f}%\")\n        print(\"\\nProbabilities for all classes:\")\n        for class_name, probability in zip(class_names, all_probabilities):\n            print(f\"{class_name}: {probability:.2f}%\")\n        \n        # Display the prediction as a bar chart\n        display_prediction(all_probabilities, class_names)\n        \n        # Print total probability\n        print(f\"\\nTotal probability: {np.sum(all_probabilities):.2f}%\")\n        \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Example usage\nimg_url = input(\"Enter the URL of the image: \")\npredict_from_url(img_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T04:00:09.551725Z","iopub.execute_input":"2024-09-13T04:00:09.55215Z","iopub.status.idle":"2024-09-13T04:10:07.289514Z","shell.execute_reply.started":"2024-09-13T04:00:09.552109Z","shell.execute_reply":"2024-09-13T04:10:07.28777Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m img_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the URL of the image: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m predict_from_url(img_url)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}]},{"cell_type":"code","source":"! pip install ipywidgets\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T04:12:32.805876Z","iopub.execute_input":"2024-09-13T04:12:32.80636Z","iopub.status.idle":"2024-09-13T04:12:50.891286Z","shell.execute_reply.started":"2024-09-13T04:12:32.806305Z","shell.execute_reply":"2024-09-13T04:12:50.889799Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.29.4)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.8)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.1)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.3)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.1.2)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\nRequirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.22.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.12.5)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\nRequirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.2)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.6.0)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20240316)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageOps\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Load both models\nmodel1 = tf.keras.models.load_model(\"/kaggle/input/isic_tm_79/keras/default/3/keras_Model_2.16.1.h5\")\nmodel2 = tf.keras.models.load_model(\"/kaggle/input/isic6k/keras/default/2/xception_model_v6.h5\")\n\n# Define class names\nclass_names = ['Basal_Cell_Carcinoma', 'Melanoma', 'Nevus', 'Benign_keratosis', 'No_cancer']\n\n# Define class-specific weights for each model\nweights_model1 = np.array([0.6, 0.6, 0.6, 0.6, 0.5])\nweights_model2 = np.array([0.4, 0.4, 0.4, 0.4, 0.5])\n\n# Preprocessing functions for both models\ndef preprocess_image_model1(img):\n    size = (224, 224)\n    img = ImageOps.fit(img, size, Image.Resampling.LANCZOS)\n    img_array = np.asarray(img)\n    img_array = (img_array.astype(np.float32) / 127.5) - 1\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef preprocess_image_model2(img):\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0).astype('float32') / 255\n    return img_array\n\n# Combined prediction function\ndef combined_predict_skin_cancer(img):\n    processed_image1 = preprocess_image_model1(img)\n    processed_image2 = preprocess_image_model2(img)\n\n    predictions1 = model1.predict(processed_image1)[0]\n    predictions2 = model2.predict(processed_image2)[0]\n\n    weighted_predictions1 = predictions1 * weights_model1\n    weighted_predictions2 = predictions2 * weights_model2\n\n    combined_predictions = weighted_predictions1 + weighted_predictions2\n    combined_predictions = combined_predictions / np.sum(combined_predictions)\n\n    predicted_class_index = np.argmax(combined_predictions)\n    predicted_class = class_names[predicted_class_index]\n    confidence = combined_predictions[predicted_class_index] * 100\n    probabilities_percentage = combined_predictions * 100\n\n    return predicted_class, confidence, probabilities_percentage\n\n# Display bar chart for predictions\ndef display_prediction(preds, class_names):\n    fig, ax = plt.subplots(figsize=(6, 3), facecolor='none')\n    fig.patch.set_alpha(0)\n    \n    confidences = preds\n    \n    ax.barh(class_names, confidences, color=['orange' if conf == max(confidences) else 'lightblue' for conf in confidences])\n    \n    ax.set_xlim(0, 100)\n    ax.set_xlabel('Confidence (%)')\n    ax.set_title('Combined Model Prediction Output')\n    ax.patch.set_alpha(0)\n    \n    for i, v in enumerate(confidences):\n        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Display the loaded image\ndef display_image(img):\n    fig, ax = plt.subplots(figsize=(4, 4), facecolor='none')\n    fig.patch.set_alpha(0)\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title('Input Image')\n    plt.show()\n\n# Prediction handler function\ndef handle_prediction(img):\n    display_image(img)\n    predicted_class, confidence, all_probabilities = combined_predict_skin_cancer(img)\n\n    print(f\"Predicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, probability in zip(class_names, all_probabilities):\n        print(f\"{class_name}: {probability:.2f}%\")\n\n    display_prediction(all_probabilities, class_names)\n\n# Load image from URL\ndef load_image_from_url(img_url):\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    return img\n\n# Load image from file\ndef load_image_from_file(file_content):\n    img = Image.open(BytesIO(file_content)).convert(\"RGB\")\n    return img\n\n# Widgets for input\nurl_input = widgets.Text(description=\"Image URL:\", placeholder=\"Enter the URL of the image\")\nfile_upload = widgets.FileUpload(accept='.png, .jpg, .jpeg', multiple=False)\nsubmit_button = widgets.Button(description=\"Submit\")\nexit_button = widgets.Button(description=\"Exit\")\noutput = widgets.Output()\n\n# Button handlers\ndef on_submit_clicked(b):\n    with output:\n        clear_output()\n        if url_input.value:\n            img = load_image_from_url(url_input.value)\n        elif file_upload.value:\n            file_content = list(file_upload.value.values())[0]['content']\n            img = load_image_from_file(file_content)\n        else:\n            print(\"Please provide a valid URL or upload a file.\")\n            return\n        handle_prediction(img)\n\ndef on_exit_clicked(b):\n    with output:\n        clear_output()\n        print(\"Application closed. You can re-run the cell to start again.\")\n\n# Link buttons to functions\nsubmit_button.on_click(on_submit_clicked)\nexit_button.on_click(on_exit_clicked)\n\n# Display widgets\ndisplay(widgets.VBox([url_input, file_upload, submit_button, exit_button, output]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T04:13:04.125716Z","iopub.execute_input":"2024-09-13T04:13:04.126182Z","iopub.status.idle":"2024-09-13T04:13:07.812431Z","shell.execute_reply.started":"2024-09-13T04:13:04.126142Z","shell.execute_reply":"2024-09-13T04:13:07.811337Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Text(value='', description='Image URL:', placeholder='Enter the URL of the image'), FileUpload(","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b20cf71fa04d1480fa36c210bdf882"}},"metadata":{}}]}]}